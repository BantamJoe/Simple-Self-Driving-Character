{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning algorithm part\n",
    "\n",
    "Hello and wellcome to machine learning algorithm notebook! In this notebook we gonna to build, train & evaluate machine learning algorithm using dimensionality reduction technique, data augmentation and underfitting ideas from previous notebook. First of all, let's import all necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt                                 \n",
    "import pandas as pd                                      \n",
    "import numpy as np                                   \n",
    "\n",
    "import io                                                # operations with file\n",
    "import socket                                            # Socket Server\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier         # Neural Network\n",
    "from sklearn.metrics import classification_report        # Classification metrics\n",
    "from sklearn.preprocessing import normalize              # Data normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image                                    # operations with images\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dowloading\n",
    "Now we gonna to download the \"labels.csv\" file with names of all images and their labels by specific path (path in your case can be different):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image name</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lidar_2_16_2018 5_00_18 PM_66.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lidar_2_16_2018 5_00_18 PM_123.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lidar_2_16_2018 5_00_18 PM_184.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lidar_2_16_2018 5_00_18 PM_235.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lidar_2_16_2018 5_00_18 PM_284.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Image name  Direction\n",
       "0   Lidar_2_16_2018 5_00_18 PM_66.jpg          1\n",
       "1  Lidar_2_16_2018 5_00_18 PM_123.jpg          1\n",
       "2  Lidar_2_16_2018 5_00_18 PM_184.jpg          1\n",
       "3  Lidar_2_16_2018 5_00_18 PM_235.jpg          1\n",
       "4  Lidar_2_16_2018 5_00_18 PM_284.jpg          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathToImages = 'C:/Users/User/Desktop/Polygon/Dataset/'\n",
    "dataTable = pd.read_csv(pathToImages + 'labels.csv', header = 0, index_col = None)\n",
    "train = []\n",
    "labels = []\n",
    "\n",
    "# Labels: 1 - forward; 2 - rightward; 3 - stop; 4 - leftward;\n",
    "\n",
    "dataTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "Also we will download all the images and apply dimensionality reduction technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Convert images with size 180x64 to vectors of length 180\n",
    "for filename in dataTable['Image name']:\n",
    "    imagePixels = []\n",
    "    image = Image.open((pathToImages + 'images/' +  filename)) #Can be many different formats.\n",
    "    pixels = list(image.getdata())\n",
    "    for i in range(image.size[0]):\n",
    "        imagePixels.append(np.mean(pixels[i::180]))\n",
    "    train.append(imagePixels)\n",
    "        \n",
    "# Save the labels of the images\n",
    "labels = list(dataTable['Direction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Now we need to generate new data from the existing dataset, to decrease imbalance in data content. Also don't forget to normalize data and split for train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Synthesizing data: vertical inverting of images\n",
    "for i in range(len(dataTable['Direction'])):\n",
    "    train.append(train[i][::-1])\n",
    "    if labels[i] == 2:\n",
    "        labels.append(4)\n",
    "    elif labels[i] == 4:\n",
    "        labels.append(2)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 26880\n",
      "\n",
      "Train example: \n",
      "[ 31.703125   31.703125   31.703125   31.703125   31.703125   31.703125\n",
      "  31.703125   31.703125   31.703125   31.7291667  31.7916667  32.390625\n",
      "  32.46875    33.1145833  33.21875    33.265625   32.7916667  32.828125\n",
      "  32.9166667  33.5572917  33.4375     33.9270833  34.         34.015625\n",
      "  34.609375   34.6510417  34.84375    35.203125   35.3802083  35.9635417\n",
      "  36.2291667  36.265625   36.7552083  36.7708333  37.3177083  37.9583333\n",
      "  38.09375    38.5989583  39.078125   39.046875   40.0989583  40.1614583\n",
      "  40.5885417  41.0989583  42.0677083  42.6875     43.3645833  43.4791667\n",
      "  44.3177083  44.4791667  45.203125   45.7708333  46.7864583  47.3385417\n",
      "  47.7760417  48.0833333  49.5677083  49.984375   50.765625   51.7083333\n",
      "  52.4166667  53.53125    54.296875   54.84375    56.0572917  56.7447917\n",
      "  58.1822917  58.984375   59.6822917  60.8229167  61.7291667  62.4583333\n",
      "  63.515625   64.265625   65.1302083  66.0885417  66.6614583  66.859375\n",
      "  66.7135417  66.6145833  66.1510417  66.1510417  66.1510417  66.1510417\n",
      "  66.1510417  66.1510417  66.1510417  66.1510417  66.1510417  66.1510417\n",
      "  66.1510417  66.1510417  66.1510417  66.1510417  66.1510417  66.1510417\n",
      "  66.2083333  66.203125   66.2291667  66.3020833  66.28125    66.4479167\n",
      "  66.4739583  66.421875   66.5729167  66.59375    66.6145833  66.875\n",
      "  66.9114583  67.0989583  67.140625   67.140625   67.7864583  67.4010417\n",
      "  66.9947917  68.8541667  68.90625    71.1197917  55.2864583  53.015625\n",
      "  52.40625    52.046875   51.1822917  50.5833333  50.25       48.7552083\n",
      "  47.8854167  47.484375   46.3802083  46.203125   45.1979167  44.3072917\n",
      "  43.46875    42.8333333  42.0885417  41.9635417  41.0677083  41.203125\n",
      "  40.828125   40.203125   39.3802083  38.9010417  38.359375   38.2552083\n",
      "  37.7708333  37.7135417  37.0833333  36.5885417  36.3958333  35.8697917\n",
      "  35.5208333  35.3958333  34.859375   34.8020833  34.9114583  34.4322917\n",
      "  34.359375   33.875      33.7760417  33.828125   33.6979167  33.6458333\n",
      "  33.546875   32.90625    32.8072917  32.3072917  32.1875     32.0416667\n",
      "  31.8854167  31.875      31.8645833  31.9322917  31.9270833  31.828125\n",
      "  31.7864583  31.7864583  31.5260417  31.5260417  31.5260417  31.5260417]\n",
      "\n",
      "Normalized example: \n",
      "[ 0.44577078  0.44577078  0.44577078  0.44577078  0.44577078  0.44577078\n",
      "  0.44577078  0.44577078  0.44577078  0.44613695  0.44701575  0.45543757\n",
      "  0.45653607  0.46561699  0.46708166  0.46774075  0.46107653  0.46158916\n",
      "  0.46283413  0.47184182  0.47015745  0.47704138  0.47806664  0.47828634\n",
      "  0.48663493  0.4872208   0.48993043  0.49498352  0.49747345  0.50567558\n",
      "  0.50941047  0.50992311  0.51680703  0.51702673  0.52471622  0.53372391\n",
      "  0.53562798  0.5427316   0.54946906  0.54902966  0.56382278  0.56470157\n",
      "  0.5707067   0.57788356  0.59150494  0.6002197   0.60974002  0.61135115\n",
      "  0.62314171  0.62541194  0.63559136  0.64357378  0.65785427  0.66561699\n",
      "  0.67176858  0.67608934  0.69696082  0.70281948  0.71380447  0.72705969\n",
      "  0.73701941  0.75269132  0.76345661  0.7711461   0.78820945  0.79787624\n",
      "  0.81808861  0.82936653  0.83917979  0.85521787  0.86796045  0.87821311\n",
      "  0.89307946  0.90362505  0.91578176  0.92925668  0.93731234  0.9400952\n",
      "  0.93804467  0.93665324  0.93013548  0.93013548  0.93013548  0.93013548\n",
      "  0.93013548  0.93013548  0.93013548  0.93013548  0.93013548  0.93013548\n",
      "  0.93013548  0.93013548  0.93013548  0.93013548  0.93013548  0.93013548\n",
      "  0.93094105  0.93086781  0.93123398  0.93225925  0.93196631  0.93430978\n",
      "  0.93467594  0.93394361  0.93606737  0.93636031  0.93665324  0.9403149\n",
      "  0.94082754  0.94346393  0.9440498   0.9440498   0.95313072  0.94771146\n",
      "  0.94199927  0.96814354  0.96887587  1.          0.77737093  0.74544123\n",
      "  0.73687294  0.73181985  0.71966313  0.7112413   0.70655438  0.68553643\n",
      "  0.67330648  0.66766752  0.65214207  0.64965214  0.63551813  0.62299524\n",
      "  0.61120469  0.60227023  0.59179788  0.59004028  0.57744416  0.57934822\n",
      "  0.57407543  0.56528744  0.55371659  0.54697913  0.53936287  0.53789821\n",
      "  0.53108751  0.53028195  0.52142073  0.51446357  0.51175394  0.50435738\n",
      "  0.49945075  0.49769315  0.49015013  0.48934456  0.49088246  0.484145\n",
      "  0.48311974  0.47630904  0.47491761  0.47564995  0.47381911  0.47308678\n",
      "  0.47169535  0.46268766  0.46129623  0.45426584  0.45258147  0.45053094\n",
      "  0.44833394  0.44818748  0.44804101  0.44899304  0.44891981  0.44752838\n",
      "  0.44694251  0.44694251  0.44328085  0.44328085  0.44328085  0.44328085]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "normal = normalize(train, norm='max')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normal, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Total images: \" + str(len(train)))\n",
    "\n",
    "print(\"\\nTrain example: \")\n",
    "print(np.around(train[0], decimals = 7))\n",
    "print(\"\\nNormalized example: \")\n",
    "print(normal[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "\n",
    "As model we will use neural network. Sklearn already has realisation of multilayer perceptron, so we will apply it. Remember that we need to underfit our model a little bit to make it more adequate! So in our case approximately ~90% accuracy on train/test sets should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(20), max_iter=2000, activation='logistic', learning_rate_init=0.00001, \n",
    "                           learning_rate='adaptive', random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=20, learning_rate='adaptive',\n",
       "       learning_rate_init=1e-05, max_iter=2000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.96      0.95     16425\n",
      "          2       0.92      0.86      0.89      3870\n",
      "          4       0.88      0.88      0.88      3897\n",
      "\n",
      "avg / total       0.93      0.93      0.93     24192\n",
      "\n",
      "Test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.95      0.95      1817\n",
      "          2       0.94      0.85      0.89       449\n",
      "          4       0.86      0.91      0.88       422\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print(classification_report(y_train, classifier.predict(X_train)))\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test, classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment & Agent interaction\n",
    "This class provides the interaction between environment and agent, or model in other words. The class send the specific command from \"actionList\" and receive the lidar image from Unity. <b>Note: <i>The class work as server. So you should run this class first and then run Unity part. Because server will wait connection from Unity part.</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declaring a class\n",
    "\n",
    "class EnvironmentInteraction:\n",
    "    \n",
    "    def __init__(self, Address, Port):\n",
    "        \n",
    "        self.address = Address\n",
    "        self.port = Port\n",
    "        self.sock = socket.socket()\n",
    "        self.sock.bind((self.address, self.port))\n",
    "            \n",
    "        \n",
    "    def listen(self):\n",
    "        \n",
    "        self.sock.listen(1)\n",
    "        self.connection, self.address = self.sock.accept()\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        imagePixels = []\n",
    "        \n",
    "        self.connection.send(action.encode('utf-8'))                        # Send action to environment\n",
    "        data = self.connection.recv(128000)                                 # Get lidar image as bytes data \n",
    "        image = Image.frombytes('RGB', (180, 64), data)\n",
    "        \n",
    "        pixels = list(image.getdata())\n",
    "    \n",
    "        for i in range(image.size[0]):\n",
    "            imagePixels.append(np.mean(pixels[i::180]))\n",
    "                \n",
    "        return imagePixels\n",
    "    \n",
    "environment = EnvironmentInteraction('', 7777)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<socket.socket fd=2076, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 7777), raddr=('127.0.0.1', 49969)>\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] Удаленный хост принудительно разорвал существующее подключение",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-96a3e202305c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0minputLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0minputLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputLayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a8f0c5a33e04>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                        \u001b[1;31m# Send action to environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128000\u001b[0m\u001b[1;33m)\u001b[0m                                 \u001b[1;31m# Get lidar image as bytes data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] Удаленный хост принудительно разорвал существующее подключение"
     ]
    }
   ],
   "source": [
    "# Model execution\n",
    "\n",
    "environment.listen()\n",
    "actionList = ['forward', 'rightward', 'backward', 'leftward']\n",
    "print(environment.connection)\n",
    "\n",
    "outputLayer = 'forward'\n",
    "\n",
    "while True:\n",
    "        \n",
    "    inputLayer = environment.step(outputLayer)    \n",
    "    inputLayer = normalize([inputLayer], norm='max')\n",
    "    \n",
    "    outputLayer = actionList[int(classifier.predict(inputLayer)[0] - 1)]\n",
    "#     print(outputLayer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
